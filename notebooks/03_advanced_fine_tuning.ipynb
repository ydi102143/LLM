{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 高度なファインチューニング実習\n",
        "\n",
        "このノートブックでは、LLMのファインチューニングの高度なテクニックを学習します。\n",
        "\n",
        "## 学習目標\n",
        "- カスタムデータセットでのファインチューニング\n",
        "- 異なるファインチューニング手法の比較\n",
        "- ハイパーパラメータの最適化\n",
        "- モデルの評価と分析\n",
        "- 実用的なアプリケーションへの応用\n",
        "\n",
        "## 前提条件\n",
        "- LLM基礎実習の完了\n",
        "- PyTorchとTransformersの基本理解\n",
        "- 機械学習の基礎知識\n",
        "\n",
        "## 注意事項\n",
        "- このノートブックは計算集約的です\n",
        "- GPUの使用を強く推奨します\n",
        "- 実行時間は数時間に及ぶ場合があります\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 環境セットアップとライブラリのインポート\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. カスタムデータセットの作成\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \"\"\"カスタムデータセットクラス\"\"\"\n",
        "    \n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        # テキストの前処理\n",
        "        if isinstance(text, str):\n",
        "            # 単純なテキストの場合\n",
        "            encoding = self.tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "        else:\n",
        "            # 構造化されたテキストの場合\n",
        "            formatted_text = self.format_text(text)\n",
        "            encoding = self.tokenizer(\n",
        "                formatted_text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "        \n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "    \n",
        "    def format_text(self, text_dict):\n",
        "        \"\"\"構造化されたテキストをフォーマット\"\"\"\n",
        "        if 'instruction' in text_dict and 'response' in text_dict:\n",
        "            return f\"Instruction: {text_dict['instruction']}\\\\nResponse: {text_dict['response']}\"\n",
        "        elif 'context' in text_dict and 'question' in text_dict:\n",
        "            return f\"Context: {text_dict['context']}\\\\nQuestion: {text_dict['question']}\"\n",
        "        else:\n",
        "            return str(text_dict)\n",
        "\n",
        "def create_sample_datasets():\n",
        "    \"\"\"サンプルデータセットの作成\"\"\"\n",
        "    \n",
        "    # 1. 感情分析データセット\n",
        "    sentiment_data = {\n",
        "        'texts': [\n",
        "            \"I love this product! It's amazing!\",\n",
        "            \"This is terrible. I hate it.\",\n",
        "            \"The weather is okay today.\",\n",
        "            \"Fantastic! Best experience ever!\",\n",
        "            \"I'm so disappointed with this service.\",\n",
        "            \"It's fine, I guess.\",\n",
        "            \"Outstanding quality and great value!\",\n",
        "            \"Worst purchase I've ever made.\",\n",
        "            \"Good product, would recommend.\",\n",
        "            \"Excellent service and fast delivery!\"\n",
        "        ],\n",
        "        'labels': [1, 0, 1, 1, 0, 1, 1, 0, 1, 1]  # 0: negative, 1: positive\n",
        "    }\n",
        "    \n",
        "    # 2. 質問応答データセット\n",
        "    qa_data = {\n",
        "        'texts': [\n",
        "            {\n",
        "                'context': 'Machine learning is a subset of artificial intelligence.',\n",
        "                'question': 'What is machine learning?'\n",
        "            },\n",
        "            {\n",
        "                'context': 'Python is a popular programming language for data science.',\n",
        "                'question': 'Which language is good for data science?'\n",
        "            },\n",
        "            {\n",
        "                'context': 'Deep learning uses neural networks with multiple layers.',\n",
        "                'question': 'How does deep learning work?'\n",
        "            }\n",
        "        ],\n",
        "        'labels': [0, 1, 2]  # カテゴリ分類\n",
        "    }\n",
        "    \n",
        "    # 3. テキスト生成データセット\n",
        "    generation_data = {\n",
        "        'texts': [\n",
        "            {\n",
        "                'instruction': 'Write a haiku about artificial intelligence',\n",
        "                'response': 'Silent circuits hum\\\\nLearning patterns in the void\\\\nMind awakens new'\n",
        "            },\n",
        "            {\n",
        "                'instruction': 'Explain quantum computing simply',\n",
        "                'response': 'Quantum computing uses quantum bits that can exist in multiple states simultaneously, allowing for parallel processing.'\n",
        "            },\n",
        "            {\n",
        "                'instruction': 'Create a recipe for chocolate cake',\n",
        "                'response': 'Mix flour, sugar, cocoa powder, baking powder, and salt. Add eggs, milk, oil, and vanilla. Bake at 350°F for 30 minutes.'\n",
        "            }\n",
        "        ],\n",
        "        'labels': [0, 1, 2]  # タスクタイプ\n",
        "    }\n",
        "    \n",
        "    return sentiment_data, qa_data, generation_data\n",
        "\n",
        "# データセットの作成\n",
        "sentiment_data, qa_data, generation_data = create_sample_datasets()\n",
        "\n",
        "print(\"📊 サンプルデータセットが作成されました\")\n",
        "print(f\"感情分析データ: {len(sentiment_data['texts'])}件\")\n",
        "print(f\"質問応答データ: {len(qa_data['texts'])}件\")\n",
        "print(f\"テキスト生成データ: {len(generation_data['texts'])}件\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 必要なライブラリのインストール\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers datasets accelerate evaluate scikit-learn pandas numpy matplotlib seaborn tqdm wandb\n",
        "!pip install peft bitsandbytes  # LoRA用のライブラリ\n",
        "\n",
        "# ライブラリのインポート\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments, \n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from datasets import Dataset as HFDataset, load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 環境設定\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✅ ライブラリのインポートが完了しました\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
