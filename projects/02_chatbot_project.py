"""
ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€å®Ÿç”¨çš„ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹ç™ºã—ã¾ã™ã€‚
ä¼šè©±å±¥æ­´ã®ç®¡ç†ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä¿æŒã€é©åˆ‡ãªå¿œç­”ç”Ÿæˆã‚’å®Ÿè£…ã—ã¾ã™ã€‚
"""

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import pandas as pd
import numpy as np
import json
import os
from typing import List, Dict, Any, Tuple
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class ChatbotProject:
    """ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model_name="gpt2"):
        self.model_name = model_name
        self.tokenizer = None
        self.model = None
        self.conversation_history = []
        self.system_prompt = "You are a helpful and friendly AI assistant."
        self.max_history = 10  # ä¿æŒã™ã‚‹ä¼šè©±å±¥æ­´ã®æœ€å¤§æ•°
        self.max_length = 150  # ç”Ÿæˆã™ã‚‹æœ€å¤§é•·
        self.temperature = 0.7  # ç”Ÿæˆã®ãƒ©ãƒ³ãƒ€ãƒ æ€§
    
    def setup_model(self):
        """ãƒ¢ãƒ‡ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        print("ğŸ”„ ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForCausalLM.from_pretrained(self.model_name)
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            print(f"âœ… ãƒ¢ãƒ‡ãƒ« '{self.model_name}' ã®èª­ã¿è¾¼ã¿å®Œäº†")
            print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {self.model.num_parameters():,}")
            print(f"   èªå½™æ•°: {len(self.tokenizer)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            return False
    
    def add_to_history(self, role: str, content: str):
        """ä¼šè©±å±¥æ­´ã«è¿½åŠ """
        self.conversation_history.append({
            'role': role,
            'content': content,
            'timestamp': datetime.now().isoformat()
        })
        
        # å±¥æ­´ãŒé•·ã™ãã‚‹å ´åˆã¯å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
        if len(self.conversation_history) > self.max_history:
            self.conversation_history = self.conversation_history[-self.max_history:]
    
    def format_conversation(self, user_input: str) -> str:
        """ä¼šè©±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        formatted = f"{self.system_prompt}\\n\\n"
        
        # ä¼šè©±å±¥æ­´
        for message in self.conversation_history:
            if message['role'] == 'user':
                formatted += f"User: {message['content']}\\n"
            elif message['role'] == 'assistant':
                formatted += f"Assistant: {message['content']}\\n"
        
        # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
        formatted += f"User: {user_input}\\nAssistant:"
        
        return formatted
    
    def generate_response(self, user_input: str) -> str:
        """å¿œç­”ã‚’ç”Ÿæˆ"""
        if self.model is None or self.tokenizer is None:
            return "ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        
        try:
            # ä¼šè©±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            formatted_conversation = self.format_conversation(user_input)
            
            # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
            inputs = self.tokenizer.encode(formatted_conversation, return_tensors="pt")
            
            # ç”Ÿæˆ
            with torch.no_grad():
                outputs = self.model.generate(
                    inputs,
                    max_length=inputs.shape[1] + self.max_length,
                    temperature=self.temperature,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    eos_token_id=self.tokenizer.eos_token_id,
                    repetition_penalty=1.1
                )
            
            # ãƒ‡ã‚³ãƒ¼ãƒ‰
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # å¿œç­”éƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡º
            if "Assistant:" in response:
                response = response.split("Assistant:")[-1].strip()
            else:
                response = response[len(formatted_conversation):].strip()
            
            # å¿œç­”ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            response = self.clean_response(response)
            
            return response
            
        except Exception as e:
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
    
    def clean_response(self, response: str) -> str:
        """å¿œç­”ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        # ä¸è¦ãªéƒ¨åˆ†ã‚’å‰Šé™¤
        if "User:" in response:
            response = response.split("User:")[0].strip()
        
        # ç©ºã®å¿œç­”ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        if not response or len(response.strip()) < 3:
            response = "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€é©åˆ‡ãªå¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
        
        return response.strip()
    
    def chat(self, user_input: str) -> str:
        """ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½"""
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å±¥æ­´ã«è¿½åŠ 
        self.add_to_history('user', user_input)
        
        # å¿œç­”ã‚’ç”Ÿæˆ
        response = self.generate_response(user_input)
        
        # å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
        self.add_to_history('assistant', response)
        
        return response
    
    def start_interactive_chat(self):
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹"""
        print("\\nğŸ¤– ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒèµ·å‹•ã—ã¾ã—ãŸï¼")
        print("=" * 50)
        print("ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚ï¼ˆçµ‚äº†ã™ã‚‹ã«ã¯ 'quit' ã¨å…¥åŠ›ï¼‰")
        print("å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã«ã¯ 'clear' ã¨å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        print("è¨­å®šã‚’å¤‰æ›´ã™ã‚‹ã«ã¯ 'settings' ã¨å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        
        while True:
            try:
                user_input = input("\\nğŸ‘¤ ã‚ãªãŸ: ")
                
                if user_input.lower() == 'quit':
                    print("\\nğŸ‘‹ ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼")
                    break
                
                elif user_input.lower() == 'clear':
                    self.conversation_history = []
                    print("\\nğŸ—‘ï¸ ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")
                    continue
                
                elif user_input.lower() == 'settings':
                    self.show_settings()
                    continue
                
                elif not user_input.strip():
                    print("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                    continue
                
                # å¿œç­”ã‚’ç”Ÿæˆ
                response = self.chat(user_input)
                print(f"\\nğŸ¤– ãƒœãƒƒãƒˆ: {response}")
                
            except KeyboardInterrupt:
                print("\\n\\nğŸ‘‹ ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼")
                break
            except Exception as e:
                print(f"\\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                continue
    
    def show_settings(self):
        """è¨­å®šã‚’è¡¨ç¤ºãƒ»å¤‰æ›´"""
        print("\\nâš™ï¸ ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆè¨­å®š")
        print("=" * 30)
        print(f"ç¾åœ¨ã®è¨­å®š:")
        print(f"  ãƒ¢ãƒ‡ãƒ«: {self.model_name}")
        print(f"  æœ€å¤§å±¥æ­´æ•°: {self.max_history}")
        print(f"  æœ€å¤§ç”Ÿæˆé•·: {self.max_length}")
        print(f"  æ¸©åº¦: {self.temperature}")
        print(f"  ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {self.system_prompt}")
        
        print("\\nå¤‰æ›´å¯èƒ½ãªè¨­å®š:")
        print("1. æœ€å¤§å±¥æ­´æ•°")
        print("2. æœ€å¤§ç”Ÿæˆé•·")
        print("3. æ¸©åº¦")
        print("4. ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
        print("5. æˆ»ã‚‹")
        
        try:
            choice = input("\\nå¤‰æ›´ã—ãŸã„è¨­å®šã®ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ")
            
            if choice == '1':
                new_value = int(input(f"æ–°ã—ã„æœ€å¤§å±¥æ­´æ•° (ç¾åœ¨: {self.max_history}): "))
                self.max_history = max(1, min(50, new_value))
                print(f"âœ… æœ€å¤§å±¥æ­´æ•°ã‚’ {self.max_history} ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚")
            
            elif choice == '2':
                new_value = int(input(f"æ–°ã—ã„æœ€å¤§ç”Ÿæˆé•· (ç¾åœ¨: {self.max_length}): "))
                self.max_length = max(50, min(500, new_value))
                print(f"âœ… æœ€å¤§ç”Ÿæˆé•·ã‚’ {self.max_length} ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚")
            
            elif choice == '3':
                new_value = float(input(f"æ–°ã—ã„æ¸©åº¦ (ç¾åœ¨: {self.temperature}): "))
                self.temperature = max(0.1, min(2.0, new_value))
                print(f"âœ… æ¸©åº¦ã‚’ {self.temperature} ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚")
            
            elif choice == '4':
                new_prompt = input(f"æ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (ç¾åœ¨: {self.system_prompt}): ")
                if new_prompt.strip():
                    self.system_prompt = new_prompt.strip()
                    print(f"âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰æ›´ã—ã¾ã—ãŸã€‚")
            
            elif choice == '5':
                print("è¨­å®šãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            
            else:
                print("ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚")
                
        except ValueError:
            print("ç„¡åŠ¹ãªå€¤ã§ã™ã€‚")
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    def export_conversation(self, filename="conversation_history.json"):
        """ä¼šè©±å±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        print(f"\\nğŸ’¾ ä¼šè©±å±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­: {filename}")
        
        export_data = {
            'model_name': self.model_name,
            'settings': {
                'max_history': self.max_history,
                'max_length': self.max_length,
                'temperature': self.temperature,
                'system_prompt': self.system_prompt
            },
            'conversation_history': self.conversation_history,
            'export_timestamp': datetime.now().isoformat()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ä¼šè©±å±¥æ­´ã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def load_conversation(self, filename="conversation_history.json"):
        """ä¼šè©±å±¥æ­´ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.conversation_history = data.get('conversation_history', [])
            
            # è¨­å®šã‚’å¾©å…ƒ
            settings = data.get('settings', {})
            self.max_history = settings.get('max_history', self.max_history)
            self.max_length = settings.get('max_length', self.max_length)
            self.temperature = settings.get('temperature', self.temperature)
            self.system_prompt = settings.get('system_prompt', self.system_prompt)
            
            print(f"âœ… ä¼šè©±å±¥æ­´ã‚’ {filename} ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            print(f"   å±¥æ­´æ•°: {len(self.conversation_history)}ä»¶")
            
        except FileNotFoundError:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ« {filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        except Exception as e:
            print(f"âŒ èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    def demo_conversation(self):
        """ãƒ‡ãƒ¢ä¼šè©±ã‚’å®Ÿè¡Œ"""
        print("\\nğŸ­ ãƒ‡ãƒ¢ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã™")
        print("=" * 40)
        
        demo_inputs = [
            "ã“ã‚“ã«ã¡ã¯ï¼",
            "ã‚ãªãŸã¯ä½•ãŒã§ãã¾ã™ã‹ï¼Ÿ",
            "ä»Šæ—¥ã®å¤©æ°—ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
            "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ",
            "ã•ã‚ˆã†ãªã‚‰"
        ]
        
        for user_input in demo_inputs:
            print(f"\\nğŸ‘¤ ã‚ãªãŸ: {user_input}")
            response = self.chat(user_input)
            print(f"ğŸ¤– ãƒœãƒƒãƒˆ: {response}")
        
        print("\\nâœ… ãƒ‡ãƒ¢ä¼šè©±ãŒå®Œäº†ã—ã¾ã—ãŸ")
    
    def run_complete_project(self):
        """å®Œå…¨ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Ÿè¡Œ"""
        print("ğŸš€ ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é–‹å§‹ã—ã¾ã™")
        print("=" * 50)
        
        # 1. ãƒ¢ãƒ‡ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        if not self.setup_model():
            print("âŒ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’çµ‚äº†ã—ã¾ã™")
            return
        
        # 2. ãƒ‡ãƒ¢ä¼šè©±
        self.demo_conversation()
        
        # 3. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒƒãƒˆ
        self.start_interactive_chat()
        
        # 4. ä¼šè©±å±¥æ­´ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        self.export_conversation()
        
        print("\\nâœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
    print("=" * 30)
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
    chatbot = ChatbotProject()
    
    # å®Œå…¨ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Ÿè¡Œ
    chatbot.run_complete_project()

if __name__ == "__main__":
    main()
