"""
æ„Ÿæƒ…åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€å®Ÿç”¨çš„ãªæ„Ÿæƒ…åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹ç™ºã—ã¾ã™ã€‚
å®Ÿéš›ã®ãƒ“ã‚¸ãƒã‚¹ã§ä½¿ç”¨ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã®å“è³ªã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
"""

import torch
import torch.nn as nn
from transformers import (
    AutoTokenizer, 
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer
)
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import json
import os
from typing import List, Dict, Any, Tuple
import warnings
warnings.filterwarnings('ignore')

class SentimentAnalysisProject:
    """æ„Ÿæƒ…åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model_name="cardiffnlp/twitter-roberta-base-sentiment-latest"):
        self.model_name = model_name
        self.tokenizer = None
        self.model = None
        self.label_mapping = {0: "Negative", 1: "Neutral", 2: "Positive"}
        self.results = {}
    
    def setup_model(self):
        """ãƒ¢ãƒ‡ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
            
            print(f"âœ… ãƒ¢ãƒ‡ãƒ« '{self.model_name}' ã®èª­ã¿è¾¼ã¿å®Œäº†")
            print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {self.model.num_parameters():,}")
            print(f"   èªå½™æ•°: {len(self.tokenizer)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            return False
    
    def create_sample_dataset(self):
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ"""
        print("ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆä¸­...")
        
        # å®Ÿéš›ã®ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’æ¨¡æ“¬ã—ãŸã‚µãƒ³ãƒ—ãƒ«
        data = {
            'text': [
                # ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒ¬ãƒ“ãƒ¥ãƒ¼
                "I absolutely love this product! It exceeded my expectations and I would definitely buy it again.",
                "Amazing quality and fast delivery. Highly recommend to everyone!",
                "Outstanding customer service and excellent product quality.",
                "This is the best purchase I've made this year. Worth every penny!",
                "Fantastic experience from start to finish. 5 stars!",
                
                # ãƒã‚¬ãƒ†ã‚£ãƒ–ãªãƒ¬ãƒ“ãƒ¥ãƒ¼
                "Terrible product. Complete waste of money and time.",
                "Poor quality and worse customer service. Would not recommend.",
                "Disappointed with this purchase. Not as described at all.",
                "Worst experience ever. Avoid this product at all costs.",
                "Regret buying this. Money down the drain.",
                
                # ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ãªãƒ¬ãƒ“ãƒ¥ãƒ¼
                "The product is okay. Nothing special but does the job.",
                "Average quality. Expected more for the price.",
                "It's fine, I guess. Not great but not terrible either.",
                "The product works as expected. Nothing more, nothing less.",
                "Decent product but could be better. Middle of the road.",
                
                # ã‚ˆã‚Šå¤šæ§˜ãªã‚µãƒ³ãƒ—ãƒ«
                "Great value for money! The quality is surprisingly good for the price.",
                "Not impressed with the build quality. Feels cheap and flimsy.",
                "The product arrived on time and works well. Satisfied with the purchase.",
                "Overpriced for what you get. There are better alternatives available.",
                "Excellent packaging and presentation. The product itself is decent.",
                
                # è¤‡é›‘ãªæ„Ÿæƒ…è¡¨ç¾
                "I have mixed feelings about this product. The design is great but the functionality is lacking.",
                "Love the concept but the execution could be better. Still worth trying.",
                "The product has potential but needs improvement. Not ready for prime time.",
                "Good idea, poor implementation. Hope they fix the issues in the next version.",
                "Interesting product with some innovative features, but not perfect yet."
            ],
            'label': [2, 2, 2, 2, 2,  # ãƒã‚¸ãƒ†ã‚£ãƒ–
                     0, 0, 0, 0, 0,  # ãƒã‚¬ãƒ†ã‚£ãƒ–
                     1, 1, 1, 1, 1,  # ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«
                     2, 0, 2, 0, 1,  # è¿½åŠ ã‚µãƒ³ãƒ—ãƒ«
                     1, 2, 1, 0, 1]  # è¤‡é›‘ãªæ„Ÿæƒ…
        }
        
        self.df = pd.DataFrame(data)
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: {len(self.df)}ä»¶")
        print(f"   ãƒã‚¸ãƒ†ã‚£ãƒ–: {sum(self.df['label'] == 2)}ä»¶")
        print(f"   ãƒã‚¬ãƒ†ã‚£ãƒ–: {sum(self.df['label'] == 0)}ä»¶")
        print(f"   ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«: {sum(self.df['label'] == 1)}ä»¶")
        
        return self.df
    
    def analyze_dataset(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†æ"""
        print("\\nğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†æ")
        print("=" * 40)
        
        # åŸºæœ¬çµ±è¨ˆ
        print(f"ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(self.df)}")
        print(f"å¹³å‡æ–‡å­—æ•°: {self.df['text'].str.len().mean():.1f}")
        print(f"å¹³å‡å˜èªæ•°: {self.df['text'].str.split().str.len().mean():.1f}")
        
        # ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ
        label_counts = self.df['label'].value_counts().sort_index()
        print("\\nãƒ©ãƒ™ãƒ«åˆ†å¸ƒ:")
        for label, count in label_counts.items():
            sentiment = self.label_mapping[label]
            percentage = count / len(self.df) * 100
            print(f"  {sentiment}: {count}ä»¶ ({percentage:.1f}%)")
        
        # å¯è¦–åŒ–
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        
        # ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã®å††ã‚°ãƒ©ãƒ•
        axes[0].pie(label_counts.values, labels=[self.label_mapping[i] for i in label_counts.index], 
                   autopct='%1.1f%%', startangle=90)
        axes[0].set_title('æ„Ÿæƒ…åˆ†å¸ƒ')
        
        # ãƒ†ã‚­ã‚¹ãƒˆé•·ã®åˆ†å¸ƒ
        text_lengths = self.df['text'].str.len()
        axes[1].hist(text_lengths, bins=20, alpha=0.7, edgecolor='black')
        axes[1].set_xlabel('æ–‡å­—æ•°')
        axes[1].set_ylabel('é »åº¦')
        axes[1].set_title('ãƒ†ã‚­ã‚¹ãƒˆé•·ã®åˆ†å¸ƒ')
        
        plt.tight_layout()
        plt.show()
    
    def predict_sentiment(self, text):
        """å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…åˆ†æ"""
        if self.model is None or self.tokenizer is None:
            return {"error": "ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“"}
        
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, padding=True)
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
            predicted_class = torch.argmax(predictions, dim=-1).item()
            confidence = predictions[0][predicted_class].item()
        
        return {
            'text': text,
            'predicted_class': predicted_class,
            'sentiment': self.label_mapping[predicted_class],
            'confidence': confidence,
            'all_scores': {
                self.label_mapping[i]: predictions[0][i].item() 
                for i in range(len(self.label_mapping))
            }
        }
    
    def evaluate_model(self, test_data=None):
        """ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡"""
        print("\\nğŸ“Š ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡")
        print("=" * 40)
        
        if test_data is None:
            test_data = self.df
        
        predictions = []
        confidences = []
        
        for text in test_data['text']:
            result = self.predict_sentiment(text)
            predictions.append(result['predicted_class'])
            confidences.append(result['confidence'])
        
        # è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
        accuracy = accuracy_score(test_data['label'], predictions)
        f1 = f1_score(test_data['label'], predictions, average='weighted')
        
        print(f"ç²¾åº¦: {accuracy:.3f}")
        print(f"F1ã‚¹ã‚³ã‚¢: {f1:.3f}")
        
        # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
        print("\\nåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
        report = classification_report(
            test_data['label'], 
            predictions, 
            target_names=list(self.label_mapping.values())
        )
        print(report)
        
        # æ··åŒè¡Œåˆ—
        cm = confusion_matrix(test_data['label'], predictions)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=list(self.label_mapping.values()),
                   yticklabels=list(self.label_mapping.values()))
        plt.xlabel('äºˆæ¸¬')
        plt.ylabel('å®Ÿéš›')
        plt.title('æ··åŒè¡Œåˆ—')
        plt.show()
        
        # ä¿¡é ¼åº¦ã®åˆ†å¸ƒ
        plt.figure(figsize=(10, 6))
        plt.hist(confidences, bins=20, alpha=0.7, edgecolor='black')
        plt.xlabel('ä¿¡é ¼åº¦')
        plt.ylabel('é »åº¦')
        plt.title('äºˆæ¸¬ã®ä¿¡é ¼åº¦åˆ†å¸ƒ')
        plt.axvline(np.mean(confidences), color='red', linestyle='--', 
                   label=f'å¹³å‡: {np.mean(confidences):.3f}')
        plt.legend()
        plt.show()
        
        self.results = {
            'accuracy': accuracy,
            'f1_score': f1,
            'predictions': predictions,
            'confidences': confidences
        }
        
        return self.results
    
    def interactive_demo(self):
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢"""
        print("\\nğŸ® ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢")
        print("=" * 40)
        print("æ„Ÿæƒ…åˆ†æã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼ï¼ˆçµ‚äº†ã™ã‚‹ã«ã¯ 'quit' ã¨å…¥åŠ›ï¼‰")
        
        while True:
            try:
                text = input("\\nãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ")
                
                if text.lower() == 'quit':
                    print("ãƒ‡ãƒ¢ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break
                
                if not text.strip():
                    print("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                    continue
                
                result = self.predict_sentiment(text)
                
                print(f"\\nğŸ“Š åˆ†æçµæœ:")
                print(f"ãƒ†ã‚­ã‚¹ãƒˆ: {result['text']}")
                print(f"æ„Ÿæƒ…: {result['sentiment']}")
                print(f"ä¿¡é ¼åº¦: {result['confidence']:.3f}")
                print(f"è©³ç´°ã‚¹ã‚³ã‚¢:")
                for sentiment, score in result['all_scores'].items():
                    print(f"  {sentiment}: {score:.3f}")
                
            except KeyboardInterrupt:
                print("\\nãƒ‡ãƒ¢ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break
            except Exception as e:
                print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                continue
    
    def batch_analysis(self, texts):
        """ãƒãƒƒãƒåˆ†æ"""
        print(f"\\nğŸ“¦ ãƒãƒƒãƒåˆ†æ: {len(texts)}ä»¶")
        print("=" * 40)
        
        results = []
        for i, text in enumerate(texts, 1):
            result = self.predict_sentiment(text)
            results.append(result)
            print(f"{i:2d}. {text[:50]}... -> {result['sentiment']} ({result['confidence']:.3f})")
        
        return results
    
    def export_results(self, filename="sentiment_analysis_results.json"):
        """çµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        print(f"\\nğŸ’¾ çµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­: {filename}")
        
        export_data = {
            'model_name': self.model_name,
            'label_mapping': self.label_mapping,
            'results': self.results,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… çµæœã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def run_complete_project(self):
        """å®Œå…¨ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Ÿè¡Œ"""
        print("ğŸš€ æ„Ÿæƒ…åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é–‹å§‹ã—ã¾ã™")
        print("=" * 50)
        
        # 1. ãƒ¢ãƒ‡ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        if not self.setup_model():
            print("âŒ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’çµ‚äº†ã—ã¾ã™")
            return
        
        # 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
        self.create_sample_dataset()
        
        # 3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†æ
        self.analyze_dataset()
        
        # 4. ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
        self.evaluate_model()
        
        # 5. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢
        self.interactive_demo()
        
        # 6. çµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        self.export_results()
        
        print("\\nâœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("æ„Ÿæƒ…åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("æ„Ÿæƒ…åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
    print("=" * 30)
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
    project = SentimentAnalysisProject()
    
    # å®Œå…¨ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Ÿè¡Œ
    project.run_complete_project()

if __name__ == "__main__":
    main()
