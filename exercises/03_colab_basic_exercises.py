"""
LLMåŸºç¤æ¼”ç¿’å•é¡Œï¼ˆGoogle Colabç‰ˆï¼‰

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€Google Colabç’°å¢ƒã§LLMã®åŸºç¤ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®æ¼”ç¿’å•é¡ŒãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
Colabç’°å¢ƒã«æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿè£…ã«ãªã£ã¦ã„ã¾ã™ã€‚
"""

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Any, Tuple
import warnings
warnings.filterwarnings('ignore')

class ColabLLMExerciseSolver:
    """Colabç”¨LLMæ¼”ç¿’å•é¡Œè§£æ±ºã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model_name="gpt2"):
        self.model_name = model_name
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name)
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
    
    def exercise_1_basic_generation(self):
        """æ¼”ç¿’1: åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("=== æ¼”ç¿’1: åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆColabç‰ˆï¼‰ ===")
        print("ä»¥ä¸‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        
        prompts = [
            "The future of artificial intelligence is",
            "Once upon a time, there was a",
            "In the world of machine learning,"
        ]
        
        for i, prompt in enumerate(prompts, 1):
            print(f"\n--- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ {i} ---")
            print(f"å…¥åŠ›: {prompt}")
            
            # ã“ã“ã«ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„
            # ãƒ’ãƒ³ãƒˆ: generate_texté–¢æ•°ã‚’ä½¿ç”¨
            
            # è§£ç­”ä¾‹ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
            # generated = self.generate_text(prompt, max_length=80)
            # print(f"å‡ºåŠ›: {generated}")
    
    def exercise_2_parameter_tuning(self):
        """æ¼”ç¿’2: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’2: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ï¼ˆColabç‰ˆï¼‰ ===")
        print("åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç•°ãªã‚‹æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        
        prompt = "The secret to success is"
        temperatures = [0.3, 0.7, 1.0]
        
        print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
        
        for temp in temperatures:
            print(f"\næ¸©åº¦: {temp}")
            # ã“ã“ã«ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„
            # ãƒ’ãƒ³ãƒˆ: temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´
    
    def exercise_3_prompt_engineering(self):
        """æ¼”ç¿’3: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’3: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆColabç‰ˆï¼‰ ===")
        print("åŒã˜ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
        
        task = "æ„Ÿæƒ…åˆ†æ"
        text = "I absolutely love this new product!"
        
        prompt_styles = [
            f"Classify the sentiment: {text}",
            f"Determine if this is positive or negative: {text}",
            f"Analyze the emotion in this text: {text}",
            f"Rate the sentiment (positive/negative/neutral): {text}"
        ]
        
        for i, prompt in enumerate(prompt_styles, 1):
            print(f"\n--- ã‚¹ã‚¿ã‚¤ãƒ« {i} ---")
            print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
            # ã“ã“ã«ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„
    
    def exercise_4_few_shot_learning(self):
        """æ¼”ç¿’4: Few-shotå­¦ç¿’ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’4: Few-shotå­¦ç¿’ï¼ˆColabç‰ˆï¼‰ ===")
        print("ä¾‹ç¤ºã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        
        examples = [
            ("I love this movie!", "positive"),
            ("This is terrible.", "negative"),
            ("It's okay.", "neutral")
        ]
        
        query = "This is amazing!"
        
        # ã“ã“ã«Few-shotãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„
        # ãƒ’ãƒ³ãƒˆ: ä¾‹ç¤ºã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹
    
    def exercise_5_text_analysis(self):
        """æ¼”ç¿’5: ãƒ†ã‚­ã‚¹ãƒˆåˆ†æï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’5: ãƒ†ã‚­ã‚¹ãƒˆåˆ†æï¼ˆColabç‰ˆï¼‰ ===")
        print("ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹å¾´ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚")
        
        prompt = "Write a short story about a robot"
        generated_text = self.generate_text(prompt, max_length=150)
        
        print(f"ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: {generated_text}")
        
        # ã“ã“ã«åˆ†æã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„
        # ãƒ’ãƒ³ãƒˆ: æ–‡å­—æ•°ã€å˜èªæ•°ã€æ–‡æ•°ãªã©ã‚’è¨ˆç®—
    
    def exercise_6_colab_specific(self):
        """æ¼”ç¿’6: Colabå›ºæœ‰ã®æ©Ÿèƒ½"""
        print("\n=== æ¼”ç¿’6: Colabå›ºæœ‰ã®æ©Ÿèƒ½ ===")
        print("Colabç’°å¢ƒã§ã®ç‰¹æ®Šãªæ©Ÿèƒ½ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
        
        # 1. GPUä½¿ç”¨çŠ¶æ³ã®ç¢ºèª
        print("1. GPUä½¿ç”¨çŠ¶æ³:")
        if torch.cuda.is_available():
            print(f"   GPU: {torch.cuda.get_device_name(0)}")
            print(f"   ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
        else:
            print("   GPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        # 2. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®ç¢ºèª
        print("\n2. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡:")
        print(f"   ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {self.model.num_parameters():,}")
        print(f"   èªå½™æ•°: {len(self.tokenizer)}")
        
        # 3. ç”Ÿæˆé€Ÿåº¦ã®æ¸¬å®š
        print("\n3. ç”Ÿæˆé€Ÿåº¦æ¸¬å®š:")
        import time
        start_time = time.time()
        generated = self.generate_text("Test prompt", max_length=50)
        end_time = time.time()
        print(f"   ç”Ÿæˆæ™‚é–“: {end_time - start_time:.2f}ç§’")
    
    def generate_text(self, prompt, max_length=100, temperature=0.7, **kwargs):
        """ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        inputs = self.tokenizer.encode(prompt, return_tensors="pt")
        
        with torch.no_grad():
            outputs = self.model.generate(
                inputs,
                max_length=max_length,
                temperature=temperature,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id,
                **kwargs
            )
        
        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return generated_text
    
    def run_all_exercises(self):
        """ã™ã¹ã¦ã®æ¼”ç¿’ã‚’å®Ÿè¡Œï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("ğŸš€ LLMåŸºç¤æ¼”ç¿’ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆColabç‰ˆï¼‰")
        print("=" * 50)
        
        self.exercise_1_basic_generation()
        self.exercise_2_parameter_tuning()
        self.exercise_3_prompt_engineering()
        self.exercise_4_few_shot_learning()
        self.exercise_5_text_analysis()
        self.exercise_6_colab_specific()
        
        print("\nâœ… ã™ã¹ã¦ã®æ¼”ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("å„æ¼”ç¿’ã®è§£ç­”ã‚’ç¢ºèªã—ã¦ã€ç†è§£ã‚’æ·±ã‚ã¦ãã ã•ã„ã€‚")
        print("\nğŸ’¡ Colabç’°å¢ƒã§ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹:")
        print("â€¢ å®šæœŸçš„ã«ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•ã—ã¦ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢")
        print("â€¢ å¤§ããªãƒ¢ãƒ‡ãƒ«ã¯æ®µéšçš„ã«èª­ã¿è¾¼ã¿")
        print("â€¢ çµæœã¯å®šæœŸçš„ã«Google Driveã«ä¿å­˜")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("LLMåŸºç¤æ¼”ç¿’å•é¡Œï¼ˆGoogle Colabç‰ˆï¼‰")
    print("=" * 40)
    
    # æ¼”ç¿’ã‚½ãƒ«ãƒãƒ¼ã®åˆæœŸåŒ–
    solver = ColabLLMExerciseSolver()
    
    # æ¼”ç¿’ã®å®Ÿè¡Œ
    solver.run_all_exercises()

if __name__ == "__main__":
    main()
