"""
LLMé«˜åº¦æ¼”ç¿’å•é¡Œï¼ˆGoogle Colabç‰ˆï¼‰

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€Google Colabç’°å¢ƒã§LLMã®é«˜åº¦ãªæ©Ÿèƒ½ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®æ¼”ç¿’å•é¡ŒãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
Colabç’°å¢ƒã«æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿè£…ã«ãªã£ã¦ã„ã¾ã™ã€‚
"""

import torch
import torch.nn as nn
from transformers import (
    AutoTokenizer, 
    AutoModelForCausalLM,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling
)
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.model_selection import train_test_split
import json
import os
from typing import List, Dict, Any, Tuple
import warnings
warnings.filterwarnings('ignore')

class ColabAdvancedLLMExerciseSolver:
    """Colabç”¨é«˜åº¦ãªLLMæ¼”ç¿’å•é¡Œè§£æ±ºã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model_name="gpt2"):
        self.model_name = model_name
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name)
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
    
    def exercise_1_sentiment_analysis_app(self):
        """æ¼”ç¿’1: æ„Ÿæƒ…åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("=== æ¼”ç¿’1: æ„Ÿæƒ…åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆColabç‰ˆï¼‰ ===")
        print("æ„Ÿæƒ…åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
        sample_texts = [
            "I love this product! It's amazing!",
            "This is terrible. I hate it.",
            "The weather is okay today.",
            "Fantastic! Best experience ever!",
            "I'm so disappointed with this service."
        ]
        
        print("ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ:")
        for i, text in enumerate(sample_texts, 1):
            print(f"{i}. {text}")
        
        # ã“ã“ã«æ„Ÿæƒ…åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
        # ãƒ’ãƒ³ãƒˆ: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨Few-shotå­¦ç¿’ã‚’ä½¿ç”¨
        
        print("\nå®Ÿè£…ã™ã¹ãæ©Ÿèƒ½:")
        print("- ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†é¡ï¼ˆpositive/negative/neutralï¼‰")
        print("- ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®è¨ˆç®—")
        print("- ãƒãƒƒãƒå‡¦ç†ã®å¯¾å¿œ")
        print("- çµæœã®å¯è¦–åŒ–")
        print("- Colabç’°å¢ƒã§ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–")
    
    def exercise_2_text_summarization_app(self):
        """æ¼”ç¿’2: ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’2: ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆColabç‰ˆï¼‰ ===")
        print("ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
        long_text = """
        Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of "intelligent agents": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. The term "artificial intelligence" is often used to describe machines that mimic "cognitive" functions that humans associate with the human mind, such as "learning" and "problem solving". As machines become increasingly capable, tasks considered to require "intelligence" are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says "AI is whatever hasn't been done yet." For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.
        """
        
        print(f"å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ: {long_text.strip()}")
        
        # ã“ã“ã«ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
        # ãƒ’ãƒ³ãƒˆ: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’ä½¿ç”¨
        
        print("\nå®Ÿè£…ã™ã¹ãæ©Ÿèƒ½:")
        print("- é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã®è¦ç´„")
        print("- è¦ç´„ã®é•·ã•èª¿æ•´")
        print("- ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®æŠ½å‡º")
        print("- è¦ç´„å“è³ªã®è©•ä¾¡")
        print("- Colabç’°å¢ƒã§ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–")
    
    def exercise_3_question_answering_system(self):
        """æ¼”ç¿’3: è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’3: è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ï¼ˆColabç‰ˆï¼‰ ===")
        print("è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
        context = """
        Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data. It includes supervised learning, unsupervised learning, and reinforcement learning. Deep learning is a subset of machine learning that uses neural networks with multiple layers.
        """
        
        questions = [
            "What is machine learning?",
            "What are the types of machine learning?",
            "How is deep learning related to machine learning?"
        ]
        
        print(f"æ–‡è„ˆ: {context.strip()}")
        print("\nè³ªå•:")
        for i, question in enumerate(questions, 1):
            print(f"{i}. {question}")
        
        # ã“ã“ã«è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
        # ãƒ’ãƒ³ãƒˆ: æ–‡è„ˆã¨è³ªå•ã‚’çµ„ã¿åˆã‚ã›ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    
    def exercise_4_chatbot_development(self):
        """æ¼”ç¿’4: ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆé–‹ç™ºï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’4: ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆé–‹ç™ºï¼ˆColabç‰ˆï¼‰ ===")
        print("å¯¾è©±å‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚")
        
        print("å®Ÿè£…ã™ã¹ãæ©Ÿèƒ½:")
        print("- ä¼šè©±å±¥æ­´ã®ç®¡ç†")
        print("- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä¿æŒ")
        print("- é©åˆ‡ãªå¿œç­”ç”Ÿæˆ")
        print("- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°")
        print("- Colabç’°å¢ƒã§ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–")
        
        # ã“ã“ã«ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
        # ãƒ’ãƒ³ãƒˆ: ä¼šè©±å±¥æ­´ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹
    
    def exercise_5_model_fine_tuning(self):
        """æ¼”ç¿’5: ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’5: ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆColabç‰ˆï¼‰ ===")
        print("ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ãã ã•ã„ã€‚")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        sample_data = {
            'texts': [
                "This is a positive review about the product.",
                "I hate this terrible service.",
                "The quality is average, nothing special.",
                "Amazing! Highly recommend this item.",
                "Poor quality, would not buy again."
            ],
            'labels': [1, 0, 1, 1, 0]  # 0: negative, 1: positive
        }
        
        print("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:")
        for text, label in zip(sample_data['texts'], sample_data['labels']):
            print(f"ãƒ†ã‚­ã‚¹ãƒˆ: {text} | ãƒ©ãƒ™ãƒ«: {label}")
        
        # ã“ã“ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
        # ãƒ’ãƒ³ãƒˆ: TrainingArgumentsã¨Trainerã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨
        # Colabç’°å¢ƒã§ã¯è»½é‡åŒ–è¨­å®šã‚’æ¨å¥¨
    
    def exercise_6_performance_evaluation(self):
        """æ¼”ç¿’6: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’6: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ï¼ˆColabç‰ˆï¼‰ ===")
        print("ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚")
        
        print("å®Ÿè£…ã™ã¹ãè©•ä¾¡æŒ‡æ¨™:")
        print("- ç²¾åº¦ï¼ˆAccuracyï¼‰")
        print("- F1ã‚¹ã‚³ã‚¢")
        print("- æ··åŒè¡Œåˆ—")
        print("- åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ")
        print("- å¯è¦–åŒ–")
        print("- Colabç’°å¢ƒã§ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–")
        
        # ã“ã“ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
        # ãƒ’ãƒ³ãƒˆ: sklearn.metricsã‚’ä½¿ç”¨
    
    def exercise_7_hyperparameter_optimization(self):
        """æ¼”ç¿’7: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’7: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼ˆColabç‰ˆï¼‰ ===")
        print("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã—ã¦ãã ã•ã„ã€‚")
        
        print("æœ€é©åŒ–ã™ã¹ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
        print("- å­¦ç¿’ç‡ï¼ˆlearning_rateï¼‰")
        print("- ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆbatch_sizeï¼‰")
        print("- ã‚¨ãƒãƒƒã‚¯æ•°ï¼ˆnum_epochsï¼‰")
        print("- æ¸©åº¦ï¼ˆtemperatureï¼‰")
        print("- é‡ã¿æ¸›è¡°ï¼ˆweight_decayï¼‰")
        print("- Colabç’°å¢ƒã§ã®åˆ¶é™ã‚’è€ƒæ…®")
        
        # ã“ã“ã«ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
        # ãƒ’ãƒ³ãƒˆ: ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã¾ãŸã¯ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã‚’ä½¿ç”¨
        # Colabç’°å¢ƒã§ã¯è©¦è¡Œå›æ•°ã‚’åˆ¶é™
    
    def exercise_8_model_ensemble(self):
        """æ¼”ç¿’8: ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’8: ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆColabç‰ˆï¼‰ ===")
        print("è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã—ã¦ãã ã•ã„ã€‚")
        
        print("å®Ÿè£…ã™ã¹ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•:")
        print("- é‡ã¿ä»˜ãå¹³å‡")
        print("- æŠ•ç¥¨æ³•")
        print("- ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°")
        print("- ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°")
        print("- Colabç’°å¢ƒã§ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–")
        
        # ã“ã“ã«ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
        # ãƒ’ãƒ³ãƒˆ: è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’çµ„ã¿åˆã‚ã›ã‚‹
    
    def exercise_9_deployment_preparation(self):
        """æ¼”ç¿’9: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæº–å‚™ï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("\n=== æ¼”ç¿’9: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæº–å‚™ï¼ˆColabç‰ˆï¼‰ ===")
        print("æœ¬ç•ªç’°å¢ƒã§ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚’æº–å‚™ã—ã¦ãã ã•ã„ã€‚")
        
        print("å®Ÿè£…ã™ã¹ãæ©Ÿèƒ½:")
        print("- ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿")
        print("- APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ")
        print("- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°")
        print("- ãƒ­ã‚°è¨˜éŒ²")
        print("- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–")
        print("- Colabç’°å¢ƒã§ã®åˆ¶é™ã‚’è€ƒæ…®")
        
        # ã“ã“ã«ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæº–å‚™ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
        # ãƒ’ãƒ³ãƒˆ: Flaskã‚„FastAPIã‚’ä½¿ç”¨
    
    def exercise_10_colab_specific_advanced(self):
        """æ¼”ç¿’10: Colabå›ºæœ‰ã®é«˜åº¦ãªæ©Ÿèƒ½"""
        print("\n=== æ¼”ç¿’10: Colabå›ºæœ‰ã®é«˜åº¦ãªæ©Ÿèƒ½ ===")
        print("Colabç’°å¢ƒã§ã®é«˜åº¦ãªæ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚")
        
        print("å®Ÿè£…ã™ã¹ãæ©Ÿèƒ½:")
        print("- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–ã¨æœ€é©åŒ–")
        print("- æ®µéšçš„ãªãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿")
        print("- çµæœã®Google Driveä¿å­˜")
        print("- ãƒ©ãƒ³ã‚¿ã‚¤ãƒ å†èµ·å‹•ã®è‡ªå‹•åŒ–")
        print("- ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•å¾©æ—§")
        print("- é€²æ—ã®å¯è¦–åŒ–")
        
        # ã“ã“ã«Colabå›ºæœ‰ã®é«˜åº¦ãªæ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
    
    def run_all_exercises(self):
        """ã™ã¹ã¦ã®æ¼”ç¿’ã‚’å®Ÿè¡Œï¼ˆColabæœ€é©åŒ–ï¼‰"""
        print("ğŸš€ LLMé«˜åº¦æ¼”ç¿’ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆColabç‰ˆï¼‰")
        print("=" * 50)
        
        self.exercise_1_sentiment_analysis_app()
        self.exercise_2_text_summarization_app()
        self.exercise_3_question_answering_system()
        self.exercise_4_chatbot_development()
        self.exercise_5_model_fine_tuning()
        self.exercise_6_performance_evaluation()
        self.exercise_7_hyperparameter_optimization()
        self.exercise_8_model_ensemble()
        self.exercise_9_deployment_preparation()
        self.exercise_10_colab_specific_advanced()
        
        print("\nâœ… ã™ã¹ã¦ã®æ¼”ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("å„æ¼”ç¿’ã®è§£ç­”ã‚’å®Ÿè£…ã—ã¦ã€å®Ÿè·µçš„ãªã‚¹ã‚­ãƒ«ã‚’èº«ã«ã¤ã‘ã¦ãã ã•ã„ã€‚")
        print("\nğŸ’¡ Colabç’°å¢ƒã§ã®å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹:")
        print("â€¢ å®šæœŸçš„ã«ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•ã—ã¦ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢")
        print("â€¢ å¤§ããªãƒ¢ãƒ‡ãƒ«ã¯æ®µéšçš„ã«èª­ã¿è¾¼ã¿")
        print("â€¢ çµæœã¯å®šæœŸçš„ã«Google Driveã«ä¿å­˜")
        print("â€¢ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚‰è¨­å®šã‚’è»½é‡åŒ–")
        print("â€¢ é€²æ—ã¯å¯è¦–åŒ–ã—ã¦ç¢ºèª")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("LLMé«˜åº¦æ¼”ç¿’å•é¡Œï¼ˆGoogle Colabç‰ˆï¼‰")
    print("=" * 40)
    
    # æ¼”ç¿’ã‚½ãƒ«ãƒãƒ¼ã®åˆæœŸåŒ–
    solver = ColabAdvancedLLMExerciseSolver()
    
    # æ¼”ç¿’ã®å®Ÿè¡Œ
    solver.run_all_exercises()

if __name__ == "__main__":
    main()
